{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "azxclQcbWdwY"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "import os\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "import os\n",
        "import numpy as np\n",
        "import cv2\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from skimage.morphology import skeletonize\n",
        "from skimage.filters import threshold_otsu\n",
        "from skimage.measure import regionprops, label\n",
        "from scipy.ndimage import distance_transform_edt, center_of_mass\n",
        "from PIL import Image\n",
        "from collections import defaultdict\n",
        "from skimage import morphology\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "user = '7MK'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "base_dir = user+\"_inverted\"\n",
        "confusion_matrix_name = user+\"_confusion_matrix.png\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import shutil\n",
        "import random\n",
        "\n",
        "train_dir = base_dir + '_train'\n",
        "test_dir = base_dir + '_test'\n",
        "validation_dir = base_dir + '_validation'\n",
        "\n",
        "os.makedirs(train_dir, exist_ok=True)\n",
        "os.makedirs(test_dir, exist_ok=True)\n",
        "os.makedirs(validation_dir, exist_ok=True) \n",
        "\n",
        "\n",
        "for category in os.listdir(base_dir):\n",
        "    category_path = os.path.join(base_dir, category)\n",
        "    if not os.path.isdir(category_path):\n",
        "        continue\n",
        "\n",
        "    train_cat_dir = os.path.join(train_dir, category)\n",
        "    test_cat_dir = os.path.join(test_dir, category)\n",
        "    validation_cat_dir = os.path.join(validation_dir, category) \n",
        "    \n",
        "    os.makedirs(train_cat_dir, exist_ok=True)\n",
        "    os.makedirs(test_cat_dir, exist_ok=True)\n",
        "    os.makedirs(validation_cat_dir, exist_ok=True) \n",
        "\n",
        "    s1_files = []\n",
        "    other_files = []\n",
        "    for fname in os.listdir(category_path):\n",
        "        if os.path.isfile(os.path.join(category_path, fname)):\n",
        "            if '_s1_' in fname:\n",
        "                s1_files.append(fname)\n",
        "            elif '_s2_' in fname or '_s3_' in fname:\n",
        "                other_files.append(fname)\n",
        "\n",
        "    for fname in s1_files:\n",
        "        shutil.copy2(os.path.join(category_path, fname), os.path.join(test_cat_dir, fname))\n",
        "    \n",
        "    # print(f\"  Copied TEST {len(other_files)} files to '{test_cat_dir}'\")\n",
        "\n",
        "    num_test_files = 4\n",
        "    \n",
        "\n",
        "    validation_files = random.sample(other_files, num_test_files)\n",
        "    train_files = [f for f in other_files if f not in validation_files]\n",
        "\n",
        "    for fname in validation_files:\n",
        "        shutil.copy2(os.path.join(category_path, fname), os.path.join(validation_cat_dir, fname))\n",
        "    \n",
        "\n",
        "    for fname in train_files:\n",
        "        shutil.copy2(os.path.join(category_path, fname), os.path.join(train_cat_dir, fname))\n",
        "\n",
        "\n",
        "\n",
        "    print(f\"  Copied TRAIN {len(train_files)} files to '{train_cat_dir}'\")\n",
        "    print(f\"  Copied VAL {len(validation_files)} files to '{validation_cat_dir}'\")\n",
        "\n",
        "\n",
        "print(\"Done splitting files into train, validation, and test sets.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def preprocess_and_skeletonize_alternative(image):\n",
        "\n",
        "    \n",
        "    if image.shape != (224, 224, 3):\n",
        "        raise ValueError(\"Image must be of shape (224, 224, 3)\")\n",
        "    \n",
        "    gray = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)\n",
        "    \n",
        "    binary = gray > 127\n",
        "    \n",
        "    skeleton = morphology.skeletonize(binary)\n",
        "    \n",
        "    skeleton = (skeleton * 255).astype(np.uint8)\n",
        "    \n",
        "    skeleton_rgb = cv2.cvtColor(skeleton, cv2.COLOR_GRAY2RGB)\n",
        "\n",
        "    skeleton_rgb = skeleton_rgb.astype(np.float32)\n",
        "    preprocessed = tf.keras.applications.mobilenet_v2.preprocess_input(skeleton_rgb)\n",
        "    \n",
        "    return preprocessed"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MGv8SbRZWdwa"
      },
      "outputs": [],
      "source": [
        "IMAGE_SIZE = 224\n",
        "BATCH_SIZE = 8\n",
        "\n",
        "datagen = tf.keras.preprocessing.image.ImageDataGenerator(\n",
        "    preprocessing_function=preprocess_and_skeletonize_alternative\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2z4LqLLBWdwa",
        "outputId": "f43b0010-fac1-479d-de17-02d7c02abe79"
      },
      "outputs": [],
      "source": [
        "train_generator = datagen.flow_from_directory(\n",
        "    train_dir,\n",
        "    target_size=(IMAGE_SIZE, IMAGE_SIZE),\n",
        "    batch_size=BATCH_SIZE,\n",
        "    shuffle=True\n",
        ")\n",
        "\n",
        "val_generator = datagen.flow_from_directory(\n",
        "    validation_dir,\n",
        "    target_size=(IMAGE_SIZE, IMAGE_SIZE),\n",
        "    batch_size=BATCH_SIZE,\n",
        "    shuffle=False  \n",
        ")\n",
        "\n",
        "test_generator = datagen.flow_from_directory(\n",
        "    test_dir,\n",
        "    target_size=(IMAGE_SIZE, IMAGE_SIZE),\n",
        "    batch_size=BATCH_SIZE,\n",
        "    shuffle=False  \n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"Found classes:\", train_generator.class_indices)\n",
        "print(\"Samples in training set:\", train_generator.samples)\n",
        "print(\"Batches per epoch:\", train_generator.samples // train_generator.batch_size)\n",
        "print(\"Directory used:\", train_generator.directory)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TH9ZppjiWdwc"
      },
      "outputs": [],
      "source": [
        "IMG_SHAPE = (IMAGE_SIZE, IMAGE_SIZE, 3)\n",
        "\n",
        "base_model = tf.keras.applications.MobileNetV2(input_shape=IMG_SHAPE,\n",
        "                                              include_top=False,\n",
        "                                              weights=None)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SlDALlCcWdwc"
      },
      "outputs": [],
      "source": [
        "base_model.trainable = False"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H9-UNIL-Wdwc"
      },
      "source": [
        "## Add a classification head"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VfWvMwaUWdwd"
      },
      "outputs": [],
      "source": [
        "model = tf.keras.Sequential([\n",
        "  base_model,\n",
        "  tf.keras.layers.Conv2D(32, 3, activation='relu'),\n",
        "  tf.keras.layers.Dropout(0.2),\n",
        "  tf.keras.layers.GlobalAveragePooling2D(),\n",
        "  tf.keras.layers.Dense(62, activation='softmax')\n",
        "])\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "model.load_weights('baseline.weights.h5')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r9LPkKYTWdwd"
      },
      "source": [
        "## Compile the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.metrics import f1_score\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "\n",
        "class F1ScoreCallback(tf.keras.callbacks.Callback):\n",
        "    def __init__(self, val_generator):\n",
        "        super().__init__()\n",
        "        self.val_generator = val_generator\n",
        "\n",
        "    def on_epoch_end(self, epoch, logs=None):\n",
        "        y_true = []\n",
        "        y_pred = []\n",
        "        \n",
        "        for i in range(len(self.val_generator)):\n",
        "            x_val, y_val = self.val_generator[i]\n",
        "            \n",
        "            preds = self.model.predict(x_val)\n",
        "            y_true.extend(np.argmax(y_val, axis=1))\n",
        "            y_pred.extend(np.argmax(preds, axis=1))\n",
        "\n",
        "        f1 = f1_score(y_true, y_pred, average='macro')\n",
        "        print(f\" â€” val_f1_score: {f1:.4f}\")\n",
        "\n",
        "        if logs is not None:\n",
        "            logs['val_f1_score'] = f1\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Xm_jzHZsWdwd"
      },
      "outputs": [],
      "source": [
        "\n",
        "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.0005),\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        },
        "id": "7O5x_m8cWdwd",
        "outputId": "d5c462b4-ee9f-47ff-fc85-d336bac97f47"
      },
      "outputs": [],
      "source": [
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jtZ215rtWdwd",
        "outputId": "d68dd23d-40fb-46f6-cbe0-fd21e0ae4399"
      },
      "outputs": [],
      "source": [
        "print('Number of trainable variables = {}'.format(len(model.trainable_variables)))\n",
        "variables_names = [v.name for v in model.trainable_variables]\n",
        "for k in variables_names:\n",
        "    print(\"Variable: \", k)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wbhGe-cLWdwd"
      },
      "source": [
        "## Train the model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "\n",
        "early_stopping = tf.keras.callbacks.EarlyStopping(\n",
        "    monitor='val_accuracy',\n",
        "    patience=3,\n",
        "    restore_best_weights=True,\n",
        "    verbose=1\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bXJWMgGLWdwe",
        "outputId": "2bc10003-37d5-492c-9794-2ffc6246718b"
      },
      "outputs": [],
      "source": [
        "epochs = 25 \n",
        "f1_callback = F1ScoreCallback(val_generator)\n",
        "history = model.fit(train_generator, epochs=epochs, validation_data=val_generator, callbacks=[f1_callback, early_stopping])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "results = model.evaluate(test_generator, verbose=1)\n",
        "print(\"Test Loss, Test Accuracy, Test F1 Score:\", results)\n",
        "#za v4 e ova\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TZFmtS5rby-0"
      },
      "outputs": [],
      "source": [
        "weights_name = f\"{user}_per_user_weights_v1.weights.h5\"\n",
        "model.save_weights(weights_name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 564
        },
        "id": "e0745SwTWdwe",
        "outputId": "8ec8222b-27e2-479a-e04d-afaf81693adc"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "fig, ax1 = plt.subplots(figsize=(10, 6))\n",
        "\n",
        "epochs = range(1, len(history.history['accuracy']) + 1)\n",
        "\n",
        "ax1.plot(epochs, history.history['accuracy'], 'b-', label='Train Accuracy')\n",
        "ax1.plot(epochs, history.history['val_accuracy'], 'g-', label='Validation Accuracy')\n",
        "ax1.set_xlabel('Epoch')\n",
        "ax1.set_ylabel('Accuracy', color='b')\n",
        "ax1.tick_params(axis='y', labelcolor='b')\n",
        "\n",
        "ax2 = ax1.twinx()\n",
        "ax2.plot(epochs, history.history['loss'], 'r--', label='Train Loss')\n",
        "ax2.plot(epochs, history.history['val_loss'], 'm--', label='Validation Loss')\n",
        "ax2.set_ylabel('Loss', color='r')\n",
        "ax2.tick_params(axis='y', labelcolor='r')\n",
        "\n",
        "lines_1, labels_1 = ax1.get_legend_handles_labels()\n",
        "lines_2, labels_2 = ax2.get_legend_handles_labels()\n",
        "ax1.legend(lines_1 + lines_2, labels_1 + labels_2, loc='center right')\n",
        "plt.savefig(base_dir+\"train_val_loss\", dpi=300, bbox_inches='tight')\n",
        "\n",
        "plt.title('Model performance during training')\n",
        "plt.savefig(f'training_plot_user_{user}.png', dpi=300, bbox_inches='tight')\n",
        "plt.show()\n",
        "plt.close() \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IRJJdY-1Wdwe"
      },
      "source": [
        "## Save the model to a file"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8TIkDoUMWdwf"
      },
      "outputs": [],
      "source": [
        "saved_model_dir = user + 'saved_model_per_user' \n",
        "tf.saved_model.save(model, saved_model_dir)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# confusion matrix\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, classification_report"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "def analyze_confusion_pairs(cm, class_names, top_n=10):\n",
        "    print(f\"\\nMost Confused Character Pairs (Top {top_n}):\")\n",
        "    \n",
        "    confusion_pairs = []\n",
        "    for i in range(len(class_names)):\n",
        "        for j in range(len(class_names)):\n",
        "            if i != j and cm[i][j] > 0:\n",
        "                confusion_pairs.append((class_names[i], class_names[j], cm[i][j]))\n",
        "    \n",
        "    confusion_pairs.sort(key=lambda x: x[2], reverse=True)\n",
        "    \n",
        "    for i, (true_class, pred_class, count) in enumerate(confusion_pairs[:top_n]):\n",
        "        print(f\"{i+1:2d}. '{true_class}' confused as '{pred_class}'\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def plot_confusion_matrix_and_report(model, data_generator):\n",
        "    y_true = []\n",
        "    y_pred = []\n",
        "    \n",
        "    print(\"Conf  matrix...\")\n",
        "    for i in range(len(data_generator)):\n",
        "        x_batch, y_batch = data_generator[i]\n",
        "        preds = model.predict(x_batch, verbose=0) \n",
        "        y_true.extend(np.argmax(y_batch, axis=1))\n",
        "        y_pred.extend(np.argmax(preds, axis=1))\n",
        "    \n",
        "    class_names = list(data_generator.class_indices.keys())\n",
        "    class_names = [class_names[i] for i in range(len(class_names))]\n",
        "    \n",
        "    cm = confusion_matrix(y_true, y_pred)\n",
        "    \n",
        "    cm_normalized = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
        "    \n",
        "    plt.figure(figsize=(15, 15))\n",
        "    plt.imshow(cm_normalized, interpolation='nearest', cmap='Blues')\n",
        "    tick_marks = np.arange(len(class_names))\n",
        "    class_names = [name.replace('lowercase_', '') for name in class_names]\n",
        "    plt.xticks(tick_marks, class_names, rotation=0, fontsize=9)\n",
        "    plt.yticks(tick_marks, class_names, fontsize=9)\n",
        "\n",
        "    thresh = cm_normalized.max() / 2.\n",
        "    for i in range(cm_normalized.shape[0]):\n",
        "        for j in range(cm_normalized.shape[1]):\n",
        "            val = cm_normalized[i, j]\n",
        "            if val > 0: \n",
        "                text_val = '1' if np.isclose(val, 1.0) else f'{val:.2f}'\n",
        "                plt.text(j, i, text_val,\n",
        "                         horizontalalignment=\"center\",\n",
        "                         verticalalignment=\"center\",\n",
        "                         color=\"white\" if val > thresh else \"black\",\n",
        "                         fontsize=6,\n",
        "                         fontweight='bold')\n",
        "\n",
        "    plt.xlabel('Predicted Label', fontsize=12, fontweight='bold')\n",
        "    plt.ylabel('True Label', fontsize=12, fontweight='bold') \n",
        "    plt.savefig(confusion_matrix_name, dpi=300, bbox_inches='tight')\n",
        "    # plt.tight_layout()\n",
        "    plt.show()\n",
        "    return cm_normalized\n",
        "    \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "results = model.evaluate(test_generator)\n",
        "cm = plot_confusion_matrix_and_report(model, test_generator)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "analyze_confusion_pairs(cm, list(test_generator.class_indices.keys()), top_n=20)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "ondevicetrainingtflite",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.18"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
