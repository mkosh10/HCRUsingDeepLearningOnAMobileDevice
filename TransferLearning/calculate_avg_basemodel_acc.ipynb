{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c27c2c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\marij\\miniconda3\\envs\\ondevicetrainingtflite\\lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "Starting baseline model evaluation...\n",
      "WARNING:tensorflow:From c:\\Users\\marij\\miniconda3\\envs\\ondevicetrainingtflite\\lib\\site-packages\\keras\\src\\backend.py:1398: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\Users\\marij\\miniconda3\\envs\\ondevicetrainingtflite\\lib\\site-packages\\keras\\src\\layers\\normalization\\batch_normalization.py:979: The name tf.nn.fused_batch_norm is deprecated. Please use tf.compat.v1.nn.fused_batch_norm instead.\n",
      "\n",
      "Found 19 user folders: ['7MK', 'AB3', 'AN7', 'AS5', 'BC', 'BP', 'DDJ', 'DTT', 'HJ', 'HM', 'ID', 'JK1', 'JKK', 'KP4', 'MJ8', 'MMK', 'MZ', 'SA', 'TSH']\n",
      "\n",
      "Evaluating user: 7MK\n",
      "   Test path: .\\7MK_results_final\\7MK_inverted\n",
      "Found 1939 images belonging to 62 classes.\n",
      "WARNING:tensorflow:From c:\\Users\\marij\\miniconda3\\envs\\ondevicetrainingtflite\\lib\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\Users\\marij\\miniconda3\\envs\\ondevicetrainingtflite\\lib\\site-packages\\keras\\src\\engine\\base_layer_utils.py:384: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "31/31 [==============================] - 50s 2s/step - loss: 2.2907 - accuracy: 0.4776\n",
      "7MK: Accuracy=0.4776, Loss=2.2907, Samples=1939\n",
      "\n",
      "Evaluating user: AB3\n",
      "   Test path: .\\AB3_results_final\\AB3_inverted\n",
      "Found 2167 images belonging to 62 classes.\n",
      "34/34 [==============================] - 41s 1s/step - loss: 2.0934 - accuracy: 0.4887\n",
      "AB3: Accuracy=0.4887, Loss=2.0934, Samples=2167\n",
      "\n",
      "Evaluating user: AN7\n",
      "   Test path: .\\AN7_results_final\\AN7_inverted\n",
      "Found 1884 images belonging to 62 classes.\n",
      "30/30 [==============================] - 35s 1s/step - loss: 2.1299 - accuracy: 0.4936\n",
      "AN7: Accuracy=0.4936, Loss=2.1299, Samples=1884\n",
      "\n",
      "Evaluating user: AS5\n",
      "   Test path: .\\AS5_results_final\\AS5_inverted\n",
      "Found 1946 images belonging to 62 classes.\n",
      "31/31 [==============================] - 43s 1s/step - loss: 2.7945 - accuracy: 0.4147\n",
      "AS5: Accuracy=0.4147, Loss=2.7945, Samples=1946\n",
      "\n",
      "Evaluating user: BC\n",
      "   Test path: .\\BC_results_final\\BC_inverted\n",
      "Found 2017 images belonging to 62 classes.\n",
      "32/32 [==============================] - 36s 1s/step - loss: 2.7962 - accuracy: 0.3793\n",
      "BC: Accuracy=0.3793, Loss=2.7962, Samples=2017\n",
      "\n",
      "Evaluating user: BP\n",
      "   Test path: .\\BP_results_final\\BP_inverted\n",
      "Found 1926 images belonging to 62 classes.\n",
      "31/31 [==============================] - 34s 1s/step - loss: 2.9212 - accuracy: 0.3515\n",
      "BP: Accuracy=0.3515, Loss=2.9212, Samples=1926\n",
      "\n",
      "Evaluating user: DDJ\n",
      "   Test path: .\\DDJ_results_final\\DDJ_inverted\n",
      "Found 1985 images belonging to 62 classes.\n",
      "32/32 [==============================] - 37s 1s/step - loss: 2.8187 - accuracy: 0.4484\n",
      "DDJ: Accuracy=0.4484, Loss=2.8187, Samples=1985\n",
      "\n",
      "Evaluating user: DTT\n",
      "   Test path: .\\DTT_results_final\\DTT_inverted\n",
      "Found 1946 images belonging to 62 classes.\n",
      "31/31 [==============================] - 38s 1s/step - loss: 2.2348 - accuracy: 0.4959\n",
      "DTT: Accuracy=0.4959, Loss=2.2348, Samples=1946\n",
      "\n",
      "Evaluating user: HJ\n",
      "   Test path: .\\HJ_results_final\\HJ_inverted\n",
      "Found 1958 images belonging to 62 classes.\n",
      "31/31 [==============================] - 36s 1s/step - loss: 2.6234 - accuracy: 0.4311\n",
      "HJ: Accuracy=0.4311, Loss=2.6234, Samples=1958\n",
      "\n",
      "Evaluating user: HM\n",
      "   Test path: .\\HM_results_final\\HM_inverted\n",
      "Found 2204 images belonging to 62 classes.\n",
      "35/35 [==============================] - 41s 1s/step - loss: 2.7244 - accuracy: 0.3929\n",
      "HM: Accuracy=0.3929, Loss=2.7244, Samples=2204\n",
      "\n",
      "Evaluating user: ID\n",
      "   Test path: .\\ID_results_final\\ID_inverted\n",
      "Found 1929 images belonging to 62 classes.\n",
      "31/31 [==============================] - 38s 1s/step - loss: 2.5179 - accuracy: 0.4184\n",
      "ID: Accuracy=0.4184, Loss=2.5179, Samples=1929\n",
      "\n",
      "Evaluating user: JK1\n",
      "   Test path: .\\JK1_results_final\\JK1_inverted\n",
      "Found 1866 images belonging to 62 classes.\n",
      "30/30 [==============================] - 36s 1s/step - loss: 2.3266 - accuracy: 0.4962\n",
      "JK1: Accuracy=0.4962, Loss=2.3266, Samples=1866\n",
      "\n",
      "Evaluating user: JKK\n",
      "   Test path: .\\JKK_results_final\\JKK_inverted\n",
      "Found 1866 images belonging to 62 classes.\n",
      "30/30 [==============================] - 36s 1s/step - loss: 2.6322 - accuracy: 0.4716\n",
      "JKK: Accuracy=0.4716, Loss=2.6322, Samples=1866\n",
      "\n",
      "Evaluating user: KP4\n",
      "   Test path: .\\KP4_results_final\\KP4_inverted\n",
      "Found 1927 images belonging to 62 classes.\n",
      "31/31 [==============================] - 36s 1s/step - loss: 2.9749 - accuracy: 0.3607\n",
      "KP4: Accuracy=0.3607, Loss=2.9749, Samples=1927\n",
      "\n",
      "Evaluating user: MJ8\n",
      "   Test path: .\\MJ8_results_final\\MJ8_inverted\n",
      "Found 1893 images belonging to 62 classes.\n",
      "30/30 [==============================] - 36s 1s/step - loss: 3.1510 - accuracy: 0.3904\n",
      "MJ8: Accuracy=0.3904, Loss=3.1510, Samples=1893\n",
      "\n",
      "Evaluating user: MMK\n",
      "   Test path: .\\MMK_results_final\\MMK_inverted\n",
      "Found 1898 images belonging to 62 classes.\n",
      "30/30 [==============================] - 35s 1s/step - loss: 2.7483 - accuracy: 0.4357\n",
      "MMK: Accuracy=0.4357, Loss=2.7483, Samples=1898\n",
      "\n",
      "Evaluating user: MZ\n",
      "   Test path: .\\MZ_results_final\\MZ_inverted\n",
      "Found 1957 images belonging to 62 classes.\n",
      "31/31 [==============================] - 36s 1s/step - loss: 2.8810 - accuracy: 0.4149\n",
      "MZ: Accuracy=0.4149, Loss=2.8810, Samples=1957\n",
      "\n",
      "Evaluating user: SA\n",
      "   Test path: .\\SA_results_final\\SA_inverted\n",
      "Found 1930 images belonging to 62 classes.\n",
      "31/31 [==============================] - 36s 1s/step - loss: 2.0696 - accuracy: 0.5114\n",
      "SA: Accuracy=0.5114, Loss=2.0696, Samples=1930\n",
      "\n",
      "Evaluating user: TSH\n",
      "   Test path: .\\TSH_results_final\\TSH_inverted\n",
      "Found 1986 images belonging to 62 classes.\n",
      "32/32 [==============================] - 35s 1s/step - loss: 2.7135 - accuracy: 0.4436\n",
      "TSH: Accuracy=0.4436, Loss=2.7135, Samples=1986\n",
      "\n",
      "==================================================\n",
      " BASELINE MODEL RESULTS SUMMARY\n",
      "Mean Accuracy: 0.4377 ± 0.0478\n",
      "Mean Loss: 2.6022 ± 0.3139\n",
      "Total Users Evaluated: 19\n",
      "Best User Accuracy: 0.5114\n",
      "Worst User Accuracy: 0.3515\n",
      "\n",
      "Individual Results:\n",
      "   7MK: 0.4776 (1939 samples)\n",
      "   AB3: 0.4887 (2167 samples)\n",
      "   AN7: 0.4936 (1884 samples)\n",
      "   AS5: 0.4147 (1946 samples)\n",
      "   BC: 0.3793 (2017 samples)\n",
      "   BP: 0.3515 (1926 samples)\n",
      "   DDJ: 0.4484 (1985 samples)\n",
      "   DTT: 0.4959 (1946 samples)\n",
      "   HJ: 0.4311 (1958 samples)\n",
      "   HM: 0.3929 (2204 samples)\n",
      "   ID: 0.4184 (1929 samples)\n",
      "   JK1: 0.4962 (1866 samples)\n",
      "   JKK: 0.4716 (1866 samples)\n",
      "   KP4: 0.3607 (1927 samples)\n",
      "   MJ8: 0.3904 (1893 samples)\n",
      "   MMK: 0.4357 (1898 samples)\n",
      "   MZ: 0.4149 (1957 samples)\n",
      "   SA: 0.5114 (1930 samples)\n",
      "   TSH: 0.4436 (1986 samples)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import os\n",
    "import cv2\n",
    "from skimage import morphology\n",
    "\n",
    "def preprocess_and_skeletonize_alternative(image):\n",
    "    \n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)\n",
    "    \n",
    "    binary = gray > 127\n",
    "    \n",
    "    skeleton = morphology.skeletonize(binary)\n",
    "    \n",
    "    skeleton = (skeleton * 255).astype(np.uint8)\n",
    "    \n",
    "    skeleton_rgb = cv2.cvtColor(skeleton, cv2.COLOR_GRAY2RGB)\n",
    "    \n",
    "    skeleton_rgb = skeleton_rgb.astype(np.float32)\n",
    "    preprocessed = tf.keras.applications.mobilenet_v2.preprocess_input(skeleton_rgb)\n",
    "    \n",
    "    return preprocessed\n",
    "\n",
    "def create_model():\n",
    "    IMG_SHAPE = (224, 224, 3)\n",
    "    \n",
    "    base_model = tf.keras.applications.MobileNetV2(input_shape=IMG_SHAPE,\n",
    "                                                   include_top=False,\n",
    "                                                   weights=None)\n",
    "    base_model.trainable = False\n",
    "    \n",
    "    model = tf.keras.Sequential([\n",
    "        base_model,\n",
    "        tf.keras.layers.Conv2D(32, 3, activation='relu'),\n",
    "        tf.keras.layers.Dropout(0.2),\n",
    "        tf.keras.layers.GlobalAveragePooling2D(),\n",
    "        tf.keras.layers.Dense(62, activation='softmax')\n",
    "    ])\n",
    "    \n",
    "    return model\n",
    "\n",
    "def evaluate_all_folders():\n",
    "    print(\"Starting baseline model evaluation...\")\n",
    "    \n",
    "    model = create_model()\n",
    "    model.load_weights('baseline.weights.h5') \n",
    "    \n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.0005),\n",
    "                  loss='categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "    \n",
    "    datagen = tf.keras.preprocessing.image.ImageDataGenerator(\n",
    "        preprocessing_function=preprocess_and_skeletonize_alternative\n",
    "    )\n",
    "    \n",
    "    data_root = \".\"\n",
    "    user_folders = [d for d in os.listdir(data_root) \n",
    "                   if os.path.isdir(os.path.join(data_root, d)) and d.endswith('_results_final')]\n",
    "    \n",
    "    print(f\"Found {len(user_folders)} user folders: {[d.replace('_results_final', '') for d in user_folders]}\")\n",
    "    \n",
    "    accuracies = []\n",
    "    losses = []\n",
    "    results_data = []\n",
    "    \n",
    "    for user_folder in user_folders:\n",
    "        user_initials = user_folder.replace('_results_final', '')\n",
    "        test_path = os.path.join(data_root, user_folder, f\"{user_initials}_inverted\")\n",
    "        \n",
    "        if not os.path.exists(test_path):\n",
    "            print(f\"Skipping {user_initials}: Path {test_path} not found\")\n",
    "            continue\n",
    "        \n",
    "        print(f\"\\nEvaluating user: {user_initials}\")\n",
    "        print(f\"   Test path: {test_path}\")\n",
    "        \n",
    "        test_generator = datagen.flow_from_directory(\n",
    "            test_path,\n",
    "            target_size=(224, 224),\n",
    "            batch_size=64,\n",
    "            shuffle=False,\n",
    "            class_mode='categorical'\n",
    "        )\n",
    "        \n",
    "        results = model.evaluate(test_generator, verbose=1)\n",
    "        test_loss = results[0]\n",
    "        test_accuracy = results[1]\n",
    "        \n",
    "        accuracies.append(test_accuracy)\n",
    "        losses.append(test_loss)\n",
    "        results_data.append({\n",
    "            'user': user_initials,\n",
    "            'accuracy': test_accuracy,\n",
    "            'loss': test_loss,\n",
    "            'samples': test_generator.samples\n",
    "        })\n",
    "        \n",
    "        print(f\"{user_initials}: Accuracy={test_accuracy:.4f}, Loss={test_loss:.4f}, Samples={test_generator.samples}\")\n",
    "    \n",
    "    if accuracies:\n",
    "        mean_accuracy = np.mean(accuracies)\n",
    "        std_accuracy = np.std(accuracies)\n",
    "        mean_loss = np.mean(losses)\n",
    "        std_loss = np.std(losses)\n",
    "        \n",
    "        print(\"\\n\" + \"=\"*50)\n",
    "        print(\" BASELINE MODEL RESULTS SUMMARY\")\n",
    "        print(f\"Mean Accuracy: {mean_accuracy:.4f} ± {std_accuracy:.4f}\")\n",
    "        print(f\"Mean Loss: {mean_loss:.4f} ± {std_loss:.4f}\")\n",
    "        print(f\"Total Users Evaluated: {len(accuracies)}\")\n",
    "        print(f\"Best User Accuracy: {max(accuracies):.4f}\")\n",
    "        print(f\"Worst User Accuracy: {min(accuracies):.4f}\")\n",
    "        \n",
    "        print(\"\\nIndividual Results:\")\n",
    "        for result in results_data:\n",
    "            print(f\"   {result['user']}: {result['accuracy']:.4f} ({result['samples']} samples)\")\n",
    "        \n",
    "   \n",
    "        \n",
    "        return {\n",
    "            'mean_accuracy': mean_accuracy,\n",
    "            'std_accuracy': std_accuracy,\n",
    "            'mean_loss': mean_loss,\n",
    "            'std_loss': std_loss,\n",
    "            'individual_results': results_data\n",
    "        }\n",
    "    else:\n",
    "        print(\"No user folders evaluated successfully!\")\n",
    "        return None\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    results = evaluate_all_folders()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ondevicetrainingtflite",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
